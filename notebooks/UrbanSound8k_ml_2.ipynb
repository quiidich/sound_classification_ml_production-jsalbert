{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UrbanSound8k_machine_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrVjHhS40MZM"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import librosa\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA_prGkx8N7P",
        "outputId": "159f794b-5930-4d1c-fe5d-f52c1a0dccdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz -O urban8k.tgz\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "dataset_path = '/content/gdrive/MyDrive/urbansound8k'\n",
        "shutil.copy('urban8k.tgz', os.path.join(dataset_path, 'urban8k.tgz'))\n",
        "\n",
        "!tar -xzf urban8k.tgz\n",
        "!rm urban8k.tgz"
      ],
      "metadata": {
        "id": "RXBRedMf6qCO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "dataset_path = '/content/gdrive/MyDrive/urbansound8k'\n",
        "shutil.copy(os.path.join(dataset_path, 'urban8k.tgz'), 'urban8k.tgz')\n",
        "\n",
        "!tar -xzf urban8k.tgz\n",
        "!rm urban8k.tgz"
      ],
      "metadata": {
        "id": "MA2Na1D1_LhZ",
        "outputId": "1cb8e7b6-3a03-4bea-b0ce-3d1a6d0db09d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'urbansound8k.tgz'\n",
            "tar (child): urbansound8k.tgz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n",
            "rm: cannot remove 'urbansound8k.tgz': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPbaPrONsoiY"
      },
      "source": [
        "# FeatureExtractor class including librosa audio processing functions\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv_file = csv_file\n",
        "        self.max_audio_duration = 4\n",
        "        self.dataset_df = self._create_dataset(csv_file)\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_dataset(csv_file):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataset_path: path with the .wav files after unzipping\n",
        "        Returns: A pandas dataframe with the list of files and labels (`filenames`, `labels`)\n",
        "        \"\"\"\n",
        "        dataset_df = pd.read_csv(csv_file)\n",
        "        filepaths = []\n",
        "        for i, row in dataset_df.iterrows():\n",
        "            filepaths.append(os.path.join('UrbanSound8K/audio', 'fold'+str(row['fold']), row['slice_file_name']))\n",
        "        dataset_df['filepath'] = filepaths\n",
        "        return dataset_df\n",
        "\n",
        "    @staticmethod\n",
        "    def _compute_max_pad_length(max_audio_length, sample_rate=22050, n_fft=2048, hop_length=512):\n",
        "        dummy_file = np.random.random(max_audio_length*sample_rate)\n",
        "        stft = librosa.stft(dummy_file, n_fft=n_fft, hop_length=hop_length)\n",
        "        # Return an even number for CNN computation purposes\n",
        "        if stft.shape[1] % 2 != 0:\n",
        "            return stft.shape[1] + 1\n",
        "        return stft.shape[1]\n",
        "\n",
        "    def compute_save_features(self,\n",
        "                        mode='mfcc',\n",
        "                        sample_rate=22050,\n",
        "                        n_fft=2048,\n",
        "                        hop_length=512,\n",
        "                        n_mfcc=40,\n",
        "                        output_path='features',\n",
        "                        deltas=False\n",
        "                        ):\n",
        "        dataset_features = []\n",
        "        max_pad = self._compute_max_pad_length(self.max_audio_duration,\n",
        "                                               sample_rate=sample_rate,\n",
        "                                               n_fft=n_fft,\n",
        "                                               hop_length=hop_length)\n",
        "        print('Max Padding = ', max_pad)\n",
        "\n",
        "        if not os.path.exists(output_path):\n",
        "            print('Creating output folder: ', output_path)\n",
        "            os.makedirs(output_path)\n",
        "        else:\n",
        "            print('Output folder already existed')\n",
        "\n",
        "        print('Saving features in ', output_path)\n",
        "        i = 0\n",
        "        t = time.time()\n",
        "\n",
        "        features_path = []\n",
        "        for filepath in self.dataset_df['filepath']:\n",
        "            if i % 100 == 0:\n",
        "                print('{} files processed in {}s'.format(i, time.time() - t))\n",
        "            audio_file, sample_rate = librosa.load(filepath, sr=sample_rate, res_type='kaiser_fast')\n",
        "            if mode == 'mfcc':\n",
        "                audio_features = self.compute_mfcc(audio_file, sample_rate, n_fft, hop_length, n_mfcc, deltas)\n",
        "            elif mode == 'stft':\n",
        "                audio_features = self.compute_stft(audio_file, sample_rate, n_fft, hop_length)\n",
        "            elif mode == 'mel-spectogram':\n",
        "                audio_features = self.compute_mel_spectogram(audio_file, sample_rate, n_fft, hop_length)\n",
        "\n",
        "            audio_features = np.pad(audio_features,\n",
        "                                    pad_width=((0, 0), (0, max_pad - audio_features.shape[1])))\n",
        "\n",
        "            save_path = os.path.join(output_path, filepath.split('/')[-1].replace('wav', 'npy'))\n",
        "            self.save_features(audio_features, save_path)\n",
        "            features_path.append(save_path)\n",
        "            i+=1\n",
        "        self.dataset_df['features_path'] = features_path\n",
        "        return self.dataset_df\n",
        "\n",
        "    @staticmethod\n",
        "    def save_features(audio_features, filepath):\n",
        "        np.save(filepath, audio_features)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_mel_spectogram(audio_file, sample_rate, n_fft, hop_length):\n",
        "        return librosa.feature.melspectrogram(y=audio_file,\n",
        "                                              sr=sample_rate,\n",
        "                                              n_fft=n_fft,\n",
        "                                              hop_length=hop_length)\n",
        "    @staticmethod\n",
        "    def compute_stft(audio_file, sample_rate, n_fft, hop_length):\n",
        "        return librosa.stft(y=audio_file, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_mfcc(audio_file, sample_rate, n_fft, hop_length, n_mfcc, deltas=False):\n",
        "        mfccs = librosa.feature.mfcc(y=audio_file,\n",
        "                                    sr=sample_rate,\n",
        "                                    n_fft=n_fft,\n",
        "                                    n_mfcc=n_mfcc,\n",
        "                                    )\n",
        "        # Change mode from interpolation to nearest\n",
        "        if deltas:\n",
        "          delta_mfccs = librosa.feature.delta(mfccs, mode='nearest')\n",
        "          delta2_mfccs = librosa.feature.delta(mfccs, order=2, mode='nearest')\n",
        "          return np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
        "        return mfccs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzfg9qYAH0NC"
      },
      "source": [
        "# Create dataset and extract features\n",
        "fe = FeatureExtractor('UrbanSound8K/metadata/UrbanSound8K.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resampy\n",
        "!pip install samplerate\n",
        "import resampy\n",
        "import samplerate"
      ],
      "metadata": {
        "id": "q0tK75_FhmeS",
        "outputId": "77e98412-a138-4e9f-e8ca-80f4e5568152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resampy\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.23.5)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.2\n",
            "Collecting samplerate\n",
            "  Downloading samplerate-0.1.0-py2.py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from samplerate) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from samplerate) (1.23.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->samplerate) (2.21)\n",
            "Installing collected packages: samplerate\n",
            "Successfully installed samplerate-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4wZmY8n8od-"
      },
      "source": [
        "Access to disc and librosa loading of audio files is very slow on colab Notebook (30-40 min) we could load the pre-computed features instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "Y9fa-rfjH9rn",
        "outputId": "5e3e53af-76d9-4c1d-f1af-1097aaa599d4"
      },
      "source": [
        "# Uncomment and run to compute and save features on the colab notebook\n",
        "dataset_df = fe.compute_save_features(mode='mfcc', n_mfcc=13, output_path='features_mfcc', deltas=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Padding =  174\n",
            "Output folder already existed\n",
            "Saving features in  features_mfcc\n",
            "0 files processed in 0.0002880096435546875s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-38134dc4ab84>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Uncomment and run to compute and save features on the colab notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_save_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mfcc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'features_mfcc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-46009afdc2d9>\u001b[0m in \u001b[0;36mcompute_save_features\u001b[0;34m(self, mode, sample_rate, n_fft, hop_length, n_mfcc, output_path, deltas)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} files processed in {}s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kaiser_fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mfcc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0maudio_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m         )\n\u001b[1;32m    676\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lazy_loader/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__frame_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0;34mf\"No module named '{fd['spec']}'\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;34m\"This error is lazily reported, having originally occured in\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File /usr/local/lib/python3.10/dist-packages/librosa/core/audio.py, line 32, in <module>\n\n----> resampy = lazy.load(\"resampy\")",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMMTEYMoqks_"
      },
      "source": [
        "dataset_df['features'] = [np.asarray(np.load(feature_path)) for feature_path in dataset_df['features_path']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHyfHqtKzxAE"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "dataset_df['labels_categorical'] = [to_categorical(label, 10) for label in dataset_df['classID']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfDBipkQz1RF"
      },
      "source": [
        "dataset_df.head()\n",
        "\n",
        "import pickle\n",
        "with open('dataset_df.pickle','wb') as f:\n",
        "     pickle.dump(dataset_df, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy('dataset_df.pickle', '/content/gdrive/MyDrive/urbansound8k')"
      ],
      "metadata": {
        "id": "8Ccc_VNptwBb",
        "outputId": "20de6f88-c3aa-46c7-948a-f669c947fac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/urbansound8k/dataset_df.pickle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}