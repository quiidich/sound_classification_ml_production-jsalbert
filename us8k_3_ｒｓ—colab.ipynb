{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKuduaaPf3WodFg59Ji3ij"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MrPXwMfK535I",
        "outputId": "a2526608-8460-449f-e5b2-196d0d5188ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'feature_log-mel_96_rs_df.pickle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "dataset_path = '/content/gdrive/MyDrive/Colab Notebooks'\n",
        "shutil.copy(os.path.join(dataset_path, 'feature_log-mel_96_rs_df.pickle'), 'feature_log-mel_96_rs_df.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "uRox3zpK59yk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load feature data\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('feature_log-mel_96_rs_df.pickle','rb') as f:\n",
        "    dataset_df = pickle.load(f)"
      ],
      "metadata": {
        "id": "Va-MaJN56Ad1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset\n",
        "X = np.array(dataset_df['feature'].tolist())\n",
        "y = np.array(dataset_df['label'].tolist())\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, random_state=1, stratify=y)\n",
        "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.5, random_state=1, stratify=Y_test)\n"
      ],
      "metadata": {
        "id": "iJBR66wx6EWg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add dimension for the channel\n",
        "\n",
        "X_train = X_train.reshape(-1,32,129,3)\n",
        "X_val = X_val.reshape(-1,32,129,3)\n",
        "X_test = X_test.reshape(-1,32,129,3)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYiPhKur6JFW",
        "outputId": "6c3d03af-ac40-4556-c66f-87a5f2bde9b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5097, 32, 129, 3) (1093, 32, 129, 3) (1092, 32, 129, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer learning\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "\n",
        "pre_trained_model = VGG16(weights='imagenet', include_top=False, input_shape=(32,129,3))\n",
        "pre_trained_model.summary()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(pre_trained_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.5))                          # 0.25 오버피팅 발생함\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=tf.keras.optimizers.Adam(2e-5), metrics=['acc'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7kLMb7z6MOc",
        "outputId": "6c0b9bf7-b2db-45ac-edd7-daaf2a08015e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 129, 3)]      0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 129, 64)       1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 129, 64)       36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 64, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 64, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 64, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 32, 128)        0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 32, 256)        295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 32, 256)        590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 32, 256)        590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 16, 256)        0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 16, 512)        1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 16, 512)        2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 16, 512)        2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 8, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 4, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 512)               0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14748170 (56.26 MB)\n",
            "Trainable params: 14748170 (56.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# callbacks\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='best_fcn.hdf5', # filename\n",
        "                                monitor='val_loss',   # val_accuracy 값이 개선되었을때 호출\n",
        "                                verbose=1,                # 로그 출력\n",
        "                                save_best_only=True,      # 가장 best 값 저장\n",
        "                                mode='auto')              # 알아서 best 찾음\n",
        "\n",
        "earlystopping = EarlyStopping(monitor='val_loss',  # 모니터 기준 설정 (val loss)\n",
        "                               patience=5,        # 3회 Epoch동안 개선되지 않는다면 종료\n",
        "                               verbose=1\n",
        "                              )\n",
        "\n",
        "# checkpointer = ModelCheckpoint(filepath='best_fcn.hdf5',\n",
        "#                                monitor='val_accuracy', verbose=1,\n",
        "#                                save_best_only=True)\n",
        "\n",
        "#callbacks = [checkpoint, earlystopping]\n",
        "callbacks = [checkpoint]"
      ],
      "metadata": {
        "id": "0Iskj9Y_6Qsy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run model\n",
        "\n",
        "epochs = 150\n",
        "batch_size = 256\n",
        "\n",
        "hist = model.fit(X_train, Y_train,\n",
        "              batch_size=batch_size, epochs=epochs,\n",
        "              validation_data=(X_val, Y_val), callbacks=callbacks,\n",
        "              verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLQLLgyh6VRE",
        "outputId": "a4757d49-a314-45e2-f32d-a9f7be9e9563"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 2.8866 - acc: 0.1442\n",
            "Epoch 1: val_loss improved from inf to 2.04897, saving model to best_fcn.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 42s 920ms/step - loss: 2.8866 - acc: 0.1442 - val_loss: 2.0490 - val_acc: 0.2580\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.9888 - acc: 0.2662\n",
            "Epoch 2: val_loss improved from 2.04897 to 1.65872, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 341ms/step - loss: 1.9888 - acc: 0.2662 - val_loss: 1.6587 - val_acc: 0.5023\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.6979 - acc: 0.3995\n",
            "Epoch 3: val_loss improved from 1.65872 to 1.35532, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 352ms/step - loss: 1.6979 - acc: 0.3995 - val_loss: 1.3553 - val_acc: 0.6066\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.4586 - acc: 0.4966\n",
            "Epoch 4: val_loss improved from 1.35532 to 1.11513, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 338ms/step - loss: 1.4586 - acc: 0.4966 - val_loss: 1.1151 - val_acc: 0.6715\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.2344 - acc: 0.5903\n",
            "Epoch 5: val_loss improved from 1.11513 to 0.95211, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 348ms/step - loss: 1.2344 - acc: 0.5903 - val_loss: 0.9521 - val_acc: 0.6962\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 1.0593 - acc: 0.6604\n",
            "Epoch 6: val_loss improved from 0.95211 to 0.88379, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 353ms/step - loss: 1.0593 - acc: 0.6604 - val_loss: 0.8838 - val_acc: 0.7310\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.9483 - acc: 0.6906\n",
            "Epoch 7: val_loss improved from 0.88379 to 0.82579, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 343ms/step - loss: 0.9483 - acc: 0.6906 - val_loss: 0.8258 - val_acc: 0.7438\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.8639 - acc: 0.7218\n",
            "Epoch 8: val_loss improved from 0.82579 to 0.74761, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 348ms/step - loss: 0.8639 - acc: 0.7218 - val_loss: 0.7476 - val_acc: 0.7841\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.8020 - acc: 0.7422\n",
            "Epoch 9: val_loss improved from 0.74761 to 0.69438, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 331ms/step - loss: 0.8020 - acc: 0.7422 - val_loss: 0.6944 - val_acc: 0.7832\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.7123 - acc: 0.7765\n",
            "Epoch 10: val_loss improved from 0.69438 to 0.68023, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 349ms/step - loss: 0.7123 - acc: 0.7765 - val_loss: 0.6802 - val_acc: 0.8079\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.6723 - acc: 0.7946\n",
            "Epoch 11: val_loss improved from 0.68023 to 0.62649, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 342ms/step - loss: 0.6723 - acc: 0.7946 - val_loss: 0.6265 - val_acc: 0.8051\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.6140 - acc: 0.8003\n",
            "Epoch 12: val_loss improved from 0.62649 to 0.59956, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 6s 326ms/step - loss: 0.6140 - acc: 0.8003 - val_loss: 0.5996 - val_acc: 0.8216\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.5901 - acc: 0.8134\n",
            "Epoch 13: val_loss improved from 0.59956 to 0.58582, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 347ms/step - loss: 0.5901 - acc: 0.8134 - val_loss: 0.5858 - val_acc: 0.8262\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.5513 - acc: 0.8242\n",
            "Epoch 14: val_loss improved from 0.58582 to 0.58490, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 328ms/step - loss: 0.5513 - acc: 0.8242 - val_loss: 0.5849 - val_acc: 0.8243\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4982 - acc: 0.8427\n",
            "Epoch 15: val_loss improved from 0.58490 to 0.55025, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 349ms/step - loss: 0.4982 - acc: 0.8427 - val_loss: 0.5502 - val_acc: 0.8435\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4527 - acc: 0.8548\n",
            "Epoch 16: val_loss did not improve from 0.55025\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.4527 - acc: 0.8548 - val_loss: 0.5666 - val_acc: 0.8344\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4648 - acc: 0.8532\n",
            "Epoch 17: val_loss improved from 0.55025 to 0.53325, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 331ms/step - loss: 0.4648 - acc: 0.8532 - val_loss: 0.5333 - val_acc: 0.8536\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4062 - acc: 0.8713\n",
            "Epoch 18: val_loss did not improve from 0.53325\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 0.4062 - acc: 0.8713 - val_loss: 0.5419 - val_acc: 0.8518\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3736 - acc: 0.8813\n",
            "Epoch 19: val_loss improved from 0.53325 to 0.51259, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 329ms/step - loss: 0.3736 - acc: 0.8813 - val_loss: 0.5126 - val_acc: 0.8655\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3446 - acc: 0.8886\n",
            "Epoch 20: val_loss did not improve from 0.51259\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.3446 - acc: 0.8886 - val_loss: 0.5212 - val_acc: 0.8509\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3447 - acc: 0.8909\n",
            "Epoch 21: val_loss improved from 0.51259 to 0.50311, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 345ms/step - loss: 0.3447 - acc: 0.8909 - val_loss: 0.5031 - val_acc: 0.8765\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3073 - acc: 0.9013\n",
            "Epoch 22: val_loss improved from 0.50311 to 0.50082, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 349ms/step - loss: 0.3073 - acc: 0.9013 - val_loss: 0.5008 - val_acc: 0.8646\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3019 - acc: 0.9043\n",
            "Epoch 23: val_loss did not improve from 0.50082\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 0.3019 - acc: 0.9043 - val_loss: 0.5385 - val_acc: 0.8591\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.3124 - acc: 0.8970\n",
            "Epoch 24: val_loss improved from 0.50082 to 0.48171, saving model to best_fcn.hdf5\n",
            "20/20 [==============================] - 7s 342ms/step - loss: 0.3124 - acc: 0.8970 - val_loss: 0.4817 - val_acc: 0.8783\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2641 - acc: 0.9125\n",
            "Epoch 25: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.2641 - acc: 0.9125 - val_loss: 0.5023 - val_acc: 0.8811\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2208 - acc: 0.9288\n",
            "Epoch 26: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.2208 - acc: 0.9288 - val_loss: 0.5328 - val_acc: 0.8792\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2123 - acc: 0.9296\n",
            "Epoch 27: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.2123 - acc: 0.9296 - val_loss: 0.5142 - val_acc: 0.8811\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1991 - acc: 0.9364\n",
            "Epoch 28: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.1991 - acc: 0.9364 - val_loss: 0.5117 - val_acc: 0.8783\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.2060 - acc: 0.9311\n",
            "Epoch 29: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.2060 - acc: 0.9311 - val_loss: 0.5428 - val_acc: 0.8774\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1735 - acc: 0.9449\n",
            "Epoch 30: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.1735 - acc: 0.9449 - val_loss: 0.5839 - val_acc: 0.8783\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1727 - acc: 0.9421\n",
            "Epoch 31: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.1727 - acc: 0.9421 - val_loss: 0.5578 - val_acc: 0.8838\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1664 - acc: 0.9474\n",
            "Epoch 32: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.1664 - acc: 0.9474 - val_loss: 0.5953 - val_acc: 0.8856\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1717 - acc: 0.9447\n",
            "Epoch 33: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.1717 - acc: 0.9447 - val_loss: 0.5715 - val_acc: 0.8801\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1377 - acc: 0.9547\n",
            "Epoch 34: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.1377 - acc: 0.9547 - val_loss: 0.5941 - val_acc: 0.8902\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1221 - acc: 0.9592\n",
            "Epoch 35: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 324ms/step - loss: 0.1221 - acc: 0.9592 - val_loss: 0.5984 - val_acc: 0.8838\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1408 - acc: 0.9533\n",
            "Epoch 36: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.1408 - acc: 0.9533 - val_loss: 0.5882 - val_acc: 0.8747\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1239 - acc: 0.9594\n",
            "Epoch 37: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 308ms/step - loss: 0.1239 - acc: 0.9594 - val_loss: 0.5773 - val_acc: 0.8847\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1107 - acc: 0.9629\n",
            "Epoch 38: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.1107 - acc: 0.9629 - val_loss: 0.5801 - val_acc: 0.8902\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1099 - acc: 0.9623\n",
            "Epoch 39: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.1099 - acc: 0.9623 - val_loss: 0.5947 - val_acc: 0.8838\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1054 - acc: 0.9633\n",
            "Epoch 40: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.1054 - acc: 0.9633 - val_loss: 0.6667 - val_acc: 0.8948\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1112 - acc: 0.9631\n",
            "Epoch 41: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.1112 - acc: 0.9631 - val_loss: 0.5937 - val_acc: 0.8902\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0950 - acc: 0.9682\n",
            "Epoch 42: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 320ms/step - loss: 0.0950 - acc: 0.9682 - val_loss: 0.6696 - val_acc: 0.8774\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1101 - acc: 0.9645\n",
            "Epoch 43: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 313ms/step - loss: 0.1101 - acc: 0.9645 - val_loss: 0.6143 - val_acc: 0.8856\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0835 - acc: 0.9716\n",
            "Epoch 44: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0835 - acc: 0.9716 - val_loss: 0.6256 - val_acc: 0.8930\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0825 - acc: 0.9741\n",
            "Epoch 45: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0825 - acc: 0.9741 - val_loss: 0.6291 - val_acc: 0.8911\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0856 - acc: 0.9716\n",
            "Epoch 46: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0856 - acc: 0.9716 - val_loss: 0.6882 - val_acc: 0.8902\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1191 - acc: 0.9629\n",
            "Epoch 47: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 308ms/step - loss: 0.1191 - acc: 0.9629 - val_loss: 0.5886 - val_acc: 0.8847\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0929 - acc: 0.9708\n",
            "Epoch 48: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0929 - acc: 0.9708 - val_loss: 0.5875 - val_acc: 0.8975\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0802 - acc: 0.9737\n",
            "Epoch 49: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0802 - acc: 0.9737 - val_loss: 0.6484 - val_acc: 0.8957\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0672 - acc: 0.9776\n",
            "Epoch 50: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0672 - acc: 0.9776 - val_loss: 0.6568 - val_acc: 0.8984\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0626 - acc: 0.9788\n",
            "Epoch 51: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0626 - acc: 0.9788 - val_loss: 0.6968 - val_acc: 0.8875\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0597 - acc: 0.9782\n",
            "Epoch 52: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0597 - acc: 0.9782 - val_loss: 0.6530 - val_acc: 0.8930\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.9855\n",
            "Epoch 53: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0501 - acc: 0.9855 - val_loss: 0.6634 - val_acc: 0.8957\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.9853\n",
            "Epoch 54: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0433 - acc: 0.9853 - val_loss: 0.6932 - val_acc: 0.8902\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0474 - acc: 0.9816\n",
            "Epoch 55: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 0.0474 - acc: 0.9816 - val_loss: 0.7547 - val_acc: 0.9012\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0596 - acc: 0.9821\n",
            "Epoch 56: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0596 - acc: 0.9821 - val_loss: 0.6755 - val_acc: 0.8893\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.1292 - acc: 0.9627\n",
            "Epoch 57: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.1292 - acc: 0.9627 - val_loss: 0.8564 - val_acc: 0.8500\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0966 - acc: 0.9706\n",
            "Epoch 58: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 313ms/step - loss: 0.0966 - acc: 0.9706 - val_loss: 0.6170 - val_acc: 0.8911\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0667 - acc: 0.9794\n",
            "Epoch 59: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0667 - acc: 0.9794 - val_loss: 0.7087 - val_acc: 0.8911\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0628 - acc: 0.9802\n",
            "Epoch 60: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0628 - acc: 0.9802 - val_loss: 0.6529 - val_acc: 0.9012\n",
            "Epoch 61/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0494 - acc: 0.9857\n",
            "Epoch 61: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0494 - acc: 0.9857 - val_loss: 0.6797 - val_acc: 0.8920\n",
            "Epoch 62/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0456 - acc: 0.9855\n",
            "Epoch 62: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0456 - acc: 0.9855 - val_loss: 0.6870 - val_acc: 0.8984\n",
            "Epoch 63/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0342 - acc: 0.9906\n",
            "Epoch 63: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0342 - acc: 0.9906 - val_loss: 0.7793 - val_acc: 0.8893\n",
            "Epoch 64/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0323 - acc: 0.9898\n",
            "Epoch 64: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0323 - acc: 0.9898 - val_loss: 0.7932 - val_acc: 0.8902\n",
            "Epoch 65/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0285 - acc: 0.9906\n",
            "Epoch 65: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0285 - acc: 0.9906 - val_loss: 0.7280 - val_acc: 0.9085\n",
            "Epoch 66/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0273 - acc: 0.9908\n",
            "Epoch 66: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 313ms/step - loss: 0.0273 - acc: 0.9908 - val_loss: 0.7465 - val_acc: 0.8984\n",
            "Epoch 67/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0321 - acc: 0.9894\n",
            "Epoch 67: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0321 - acc: 0.9894 - val_loss: 0.7510 - val_acc: 0.8984\n",
            "Epoch 68/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0251 - acc: 0.9922\n",
            "Epoch 68: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 324ms/step - loss: 0.0251 - acc: 0.9922 - val_loss: 0.7691 - val_acc: 0.8856\n",
            "Epoch 69/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0291 - acc: 0.9902\n",
            "Epoch 69: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0291 - acc: 0.9902 - val_loss: 0.7916 - val_acc: 0.8966\n",
            "Epoch 70/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0251 - acc: 0.9922\n",
            "Epoch 70: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0251 - acc: 0.9922 - val_loss: 0.8266 - val_acc: 0.9048\n",
            "Epoch 71/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0265 - acc: 0.9908\n",
            "Epoch 71: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0265 - acc: 0.9908 - val_loss: 0.8108 - val_acc: 0.9048\n",
            "Epoch 72/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0370 - acc: 0.9876\n",
            "Epoch 72: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0370 - acc: 0.9876 - val_loss: 0.7917 - val_acc: 0.8911\n",
            "Epoch 73/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0421 - acc: 0.9886\n",
            "Epoch 73: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0421 - acc: 0.9886 - val_loss: 0.8175 - val_acc: 0.8975\n",
            "Epoch 74/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0282 - acc: 0.9906\n",
            "Epoch 74: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0282 - acc: 0.9906 - val_loss: 0.9013 - val_acc: 0.9003\n",
            "Epoch 75/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0567 - acc: 0.9818\n",
            "Epoch 75: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0567 - acc: 0.9818 - val_loss: 0.7831 - val_acc: 0.8683\n",
            "Epoch 76/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0616 - acc: 0.9788\n",
            "Epoch 76: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0616 - acc: 0.9788 - val_loss: 0.7829 - val_acc: 0.8765\n",
            "Epoch 77/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0656 - acc: 0.9757\n",
            "Epoch 77: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0656 - acc: 0.9757 - val_loss: 0.7576 - val_acc: 0.9003\n",
            "Epoch 78/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0405 - acc: 0.9849\n",
            "Epoch 78: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0405 - acc: 0.9849 - val_loss: 0.7360 - val_acc: 0.8966\n",
            "Epoch 79/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0445 - acc: 0.9863\n",
            "Epoch 79: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0445 - acc: 0.9863 - val_loss: 0.7263 - val_acc: 0.8975\n",
            "Epoch 80/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0309 - acc: 0.9900\n",
            "Epoch 80: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0309 - acc: 0.9900 - val_loss: 0.7380 - val_acc: 0.8957\n",
            "Epoch 81/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0297 - acc: 0.9884\n",
            "Epoch 81: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0297 - acc: 0.9884 - val_loss: 0.7967 - val_acc: 0.8984\n",
            "Epoch 82/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0288 - acc: 0.9912\n",
            "Epoch 82: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0288 - acc: 0.9912 - val_loss: 0.8660 - val_acc: 0.8975\n",
            "Epoch 83/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0301 - acc: 0.9894\n",
            "Epoch 83: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0301 - acc: 0.9894 - val_loss: 0.8666 - val_acc: 0.9003\n",
            "Epoch 84/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0411 - acc: 0.9871\n",
            "Epoch 84: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0411 - acc: 0.9871 - val_loss: 0.8608 - val_acc: 0.8856\n",
            "Epoch 85/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0273 - acc: 0.9916\n",
            "Epoch 85: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0273 - acc: 0.9916 - val_loss: 0.8283 - val_acc: 0.9003\n",
            "Epoch 86/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.9792\n",
            "Epoch 86: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 324ms/step - loss: 0.0664 - acc: 0.9792 - val_loss: 0.7144 - val_acc: 0.8893\n",
            "Epoch 87/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0518 - acc: 0.9839\n",
            "Epoch 87: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0518 - acc: 0.9839 - val_loss: 0.7535 - val_acc: 0.8829\n",
            "Epoch 88/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0271 - acc: 0.9912\n",
            "Epoch 88: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0271 - acc: 0.9912 - val_loss: 0.7688 - val_acc: 0.9003\n",
            "Epoch 89/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0183 - acc: 0.9931\n",
            "Epoch 89: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0183 - acc: 0.9931 - val_loss: 0.8244 - val_acc: 0.9003\n",
            "Epoch 90/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0191 - acc: 0.9951\n",
            "Epoch 90: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0191 - acc: 0.9951 - val_loss: 0.8234 - val_acc: 0.9003\n",
            "Epoch 91/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0314 - acc: 0.9916\n",
            "Epoch 91: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 326ms/step - loss: 0.0314 - acc: 0.9916 - val_loss: 0.8291 - val_acc: 0.8984\n",
            "Epoch 92/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0440 - acc: 0.9861\n",
            "Epoch 92: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0440 - acc: 0.9861 - val_loss: 0.8129 - val_acc: 0.8920\n",
            "Epoch 93/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0306 - acc: 0.9910\n",
            "Epoch 93: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0306 - acc: 0.9910 - val_loss: 0.7729 - val_acc: 0.8948\n",
            "Epoch 94/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0188 - acc: 0.9943\n",
            "Epoch 94: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 324ms/step - loss: 0.0188 - acc: 0.9943 - val_loss: 0.8719 - val_acc: 0.8975\n",
            "Epoch 95/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0152 - acc: 0.9945\n",
            "Epoch 95: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0152 - acc: 0.9945 - val_loss: 0.9307 - val_acc: 0.9048\n",
            "Epoch 96/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9955\n",
            "Epoch 96: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 324ms/step - loss: 0.0157 - acc: 0.9955 - val_loss: 0.8682 - val_acc: 0.9012\n",
            "Epoch 97/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9951\n",
            "Epoch 97: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.9056 - val_acc: 0.9012\n",
            "Epoch 98/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9961\n",
            "Epoch 98: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.9163 - val_acc: 0.9122\n",
            "Epoch 99/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9941\n",
            "Epoch 99: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 0.0137 - acc: 0.9941 - val_loss: 1.0340 - val_acc: 0.9003\n",
            "Epoch 100/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0186 - acc: 0.9943\n",
            "Epoch 100: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0186 - acc: 0.9943 - val_loss: 1.1320 - val_acc: 0.8737\n",
            "Epoch 101/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0872 - acc: 0.9792\n",
            "Epoch 101: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 326ms/step - loss: 0.0872 - acc: 0.9792 - val_loss: 0.8162 - val_acc: 0.8811\n",
            "Epoch 102/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0597 - acc: 0.9833\n",
            "Epoch 102: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0597 - acc: 0.9833 - val_loss: 0.7903 - val_acc: 0.8957\n",
            "Epoch 103/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0459 - acc: 0.9855\n",
            "Epoch 103: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0459 - acc: 0.9855 - val_loss: 0.7653 - val_acc: 0.8884\n",
            "Epoch 104/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0196 - acc: 0.9941\n",
            "Epoch 104: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.7563 - val_acc: 0.9058\n",
            "Epoch 105/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.9945\n",
            "Epoch 105: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0176 - acc: 0.9945 - val_loss: 0.8948 - val_acc: 0.9021\n",
            "Epoch 106/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0170 - acc: 0.9939\n",
            "Epoch 106: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 314ms/step - loss: 0.0170 - acc: 0.9939 - val_loss: 0.9267 - val_acc: 0.9067\n",
            "Epoch 107/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0122 - acc: 0.9969\n",
            "Epoch 107: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0122 - acc: 0.9969 - val_loss: 0.8714 - val_acc: 0.9085\n",
            "Epoch 108/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9961\n",
            "Epoch 108: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0108 - acc: 0.9961 - val_loss: 0.9736 - val_acc: 0.9067\n",
            "Epoch 109/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0126 - acc: 0.9959\n",
            "Epoch 109: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 0.0126 - acc: 0.9959 - val_loss: 0.9498 - val_acc: 0.9076\n",
            "Epoch 110/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0141 - acc: 0.9959\n",
            "Epoch 110: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.8569 - val_acc: 0.9113\n",
            "Epoch 111/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0114 - acc: 0.9967\n",
            "Epoch 111: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0114 - acc: 0.9967 - val_loss: 0.9474 - val_acc: 0.9076\n",
            "Epoch 112/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.9939\n",
            "Epoch 112: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0176 - acc: 0.9939 - val_loss: 0.9043 - val_acc: 0.8948\n",
            "Epoch 113/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0157 - acc: 0.9945\n",
            "Epoch 113: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0157 - acc: 0.9945 - val_loss: 1.0685 - val_acc: 0.8939\n",
            "Epoch 114/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0312 - acc: 0.9906\n",
            "Epoch 114: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 313ms/step - loss: 0.0312 - acc: 0.9906 - val_loss: 0.7815 - val_acc: 0.8948\n",
            "Epoch 115/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0190 - acc: 0.9945\n",
            "Epoch 115: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0190 - acc: 0.9945 - val_loss: 0.8466 - val_acc: 0.9012\n",
            "Epoch 116/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0143 - acc: 0.9945\n",
            "Epoch 116: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 324ms/step - loss: 0.0143 - acc: 0.9945 - val_loss: 0.8417 - val_acc: 0.9039\n",
            "Epoch 117/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0149 - acc: 0.9965\n",
            "Epoch 117: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.7931 - val_acc: 0.9122\n",
            "Epoch 118/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.9953\n",
            "Epoch 118: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0180 - acc: 0.9953 - val_loss: 0.8366 - val_acc: 0.9048\n",
            "Epoch 119/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0144 - acc: 0.9945\n",
            "Epoch 119: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0144 - acc: 0.9945 - val_loss: 0.8274 - val_acc: 0.9039\n",
            "Epoch 120/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9951\n",
            "Epoch 120: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0137 - acc: 0.9951 - val_loss: 0.8382 - val_acc: 0.9058\n",
            "Epoch 121/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9959\n",
            "Epoch 121: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 326ms/step - loss: 0.0117 - acc: 0.9959 - val_loss: 0.8961 - val_acc: 0.9058\n",
            "Epoch 122/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0136 - acc: 0.9959\n",
            "Epoch 122: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0136 - acc: 0.9959 - val_loss: 0.9549 - val_acc: 0.9067\n",
            "Epoch 123/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.9974\n",
            "Epoch 123: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0098 - acc: 0.9974 - val_loss: 0.9959 - val_acc: 0.9039\n",
            "Epoch 124/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0175 - acc: 0.9957\n",
            "Epoch 124: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 326ms/step - loss: 0.0175 - acc: 0.9957 - val_loss: 0.9449 - val_acc: 0.8930\n",
            "Epoch 125/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0837 - acc: 0.9778\n",
            "Epoch 125: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0837 - acc: 0.9778 - val_loss: 0.9221 - val_acc: 0.8692\n",
            "Epoch 126/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0480 - acc: 0.9874\n",
            "Epoch 126: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 312ms/step - loss: 0.0480 - acc: 0.9874 - val_loss: 0.6783 - val_acc: 0.8984\n",
            "Epoch 127/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0286 - acc: 0.9914\n",
            "Epoch 127: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0286 - acc: 0.9914 - val_loss: 0.7540 - val_acc: 0.9076\n",
            "Epoch 128/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0218 - acc: 0.9929\n",
            "Epoch 128: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.7636 - val_acc: 0.9058\n",
            "Epoch 129/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0132 - acc: 0.9957\n",
            "Epoch 129: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.7805 - val_acc: 0.9094\n",
            "Epoch 130/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9949\n",
            "Epoch 130: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 307ms/step - loss: 0.0139 - acc: 0.9949 - val_loss: 0.8907 - val_acc: 0.9076\n",
            "Epoch 131/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0391 - acc: 0.9890\n",
            "Epoch 131: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0391 - acc: 0.9890 - val_loss: 0.7166 - val_acc: 0.8902\n",
            "Epoch 132/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0216 - acc: 0.9947\n",
            "Epoch 132: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0216 - acc: 0.9947 - val_loss: 0.7556 - val_acc: 0.9094\n",
            "Epoch 133/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.9969\n",
            "Epoch 133: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0106 - acc: 0.9969 - val_loss: 0.8790 - val_acc: 0.9131\n",
            "Epoch 134/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0075 - acc: 0.9980\n",
            "Epoch 134: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 323ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.8563 - val_acc: 0.9131\n",
            "Epoch 135/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0070 - acc: 0.9973\n",
            "Epoch 135: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0070 - acc: 0.9973 - val_loss: 0.8844 - val_acc: 0.9140\n",
            "Epoch 136/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9974\n",
            "Epoch 136: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 313ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.9616 - val_acc: 0.9094\n",
            "Epoch 137/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9971\n",
            "Epoch 137: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 0.0083 - acc: 0.9971 - val_loss: 0.9109 - val_acc: 0.9076\n",
            "Epoch 138/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.9961\n",
            "Epoch 138: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 311ms/step - loss: 0.0108 - acc: 0.9961 - val_loss: 1.0089 - val_acc: 0.9048\n",
            "Epoch 139/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0143 - acc: 0.9947\n",
            "Epoch 139: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 314ms/step - loss: 0.0143 - acc: 0.9947 - val_loss: 1.0083 - val_acc: 0.9048\n",
            "Epoch 140/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0194 - acc: 0.9949\n",
            "Epoch 140: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 310ms/step - loss: 0.0194 - acc: 0.9949 - val_loss: 0.8378 - val_acc: 0.9012\n",
            "Epoch 141/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0110 - acc: 0.9976\n",
            "Epoch 141: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 324ms/step - loss: 0.0110 - acc: 0.9976 - val_loss: 0.8231 - val_acc: 0.9058\n",
            "Epoch 142/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0139 - acc: 0.9959\n",
            "Epoch 142: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.8621 - val_acc: 0.9039\n",
            "Epoch 143/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0180 - acc: 0.9937\n",
            "Epoch 143: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0180 - acc: 0.9937 - val_loss: 0.8923 - val_acc: 0.8948\n",
            "Epoch 144/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0153 - acc: 0.9959\n",
            "Epoch 144: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 325ms/step - loss: 0.0153 - acc: 0.9959 - val_loss: 0.8932 - val_acc: 0.9039\n",
            "Epoch 145/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0113 - acc: 0.9967\n",
            "Epoch 145: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0113 - acc: 0.9967 - val_loss: 0.8909 - val_acc: 0.9067\n",
            "Epoch 146/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9976\n",
            "Epoch 146: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 324ms/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.9141 - val_acc: 0.9122\n",
            "Epoch 147/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9961\n",
            "Epoch 147: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 309ms/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.9710 - val_acc: 0.9067\n",
            "Epoch 148/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0076 - acc: 0.9969\n",
            "Epoch 148: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 322ms/step - loss: 0.0076 - acc: 0.9969 - val_loss: 0.9240 - val_acc: 0.9094\n",
            "Epoch 149/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9980\n",
            "Epoch 149: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 326ms/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.8821 - val_acc: 0.9103\n",
            "Epoch 150/150\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.0093 - acc: 0.9973\n",
            "Epoch 150: val_loss did not improve from 0.48171\n",
            "20/20 [==============================] - 6s 321ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.9443 - val_acc: 0.9094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "\n",
        "best_model = load_model('best_fcn.hdf5')\n",
        "score = best_model.evaluate(X_train, Y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "score = best_model.evaluate(X_val, Y_val, verbose=0)\n",
        "print(\"Validation Accuracy: \", score[1])\n",
        "score = best_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])\n"
      ],
      "metadata": {
        "id": "jcsXYmzF6WsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot trend of accuracy & loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(14,6))\n",
        "ax1 = plt.subplot(1,2,1)\n",
        "ax1.plot(hist.history['acc'], label='train')\n",
        "ax1.plot(hist.history['val_acc'], label='validation')\n",
        "ax1.set_title('Accuracy Trend')\n",
        "ax1.set_ylabel('accuracy')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.legend(loc='best')\n",
        "ax1.grid()\n",
        "ax2 = plt.subplot(1,2,2)\n",
        "ax2.plot(hist.history['loss'], label='train')\n",
        "ax2.plot(hist.history['val_loss'], label='validation')\n",
        "ax2.set_title('Loss Trend')\n",
        "ax2.set_ylabel('loss')\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.legend(loc='best')\n",
        "ax2.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lKt2PYiI6aGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusion matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "Y_pred = best_model.predict(X_test)\n",
        "cm = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
        "\n",
        "class_dic = {3: 'dog_bark', 2: 'children_playing', 1: 'car_horn',\n",
        "              0: 'air_conditioner', 9: 'street_music', 6: 'gun_shot',\n",
        "              8: 'siren', 5: 'engine_idling', 7: 'jackhammer', 4: 'drilling'}\n",
        "classes = [class_dic[key] for key in sorted(class_dic.keys())]\n",
        "\n",
        "normalize = True\n",
        "\n",
        "if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index =[i for i in classes],columns=[i for i in classes])\n",
        "\n",
        "plt.figure(figsize=(16,12))\n",
        "plt.title('Confusion Matrix')\n",
        "sns.heatmap(df_cm,annot=True)\n"
      ],
      "metadata": {
        "id": "_BSlNIkH6bPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a confusion matrix\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "Y_pred = best_model.predict(X_test)\n",
        "matrix = metrics.confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
        "\n",
        "# Confusion matrix code (from https://github.com/triagemd/keras-eval/blob/master/keras_eval/visualizer.py)\n",
        "def plot_confusion_matrix(cm, concepts, normalize=False, show_text=True, fontsize=18, figsize=(16, 12),\n",
        "                          cmap=plt.cm.coolwarm_r, save_path=None, show_labels=True):\n",
        "\n",
        "    if cm.ndim != 2 or cm.shape[0] != cm.shape[1]:\n",
        "        raise ValueError('Invalid confusion matrix shape, it should be square and ndim=2')\n",
        "\n",
        "    if cm.shape[0] != len(concepts) or cm.shape[1] != len(concepts):\n",
        "        raise ValueError('Number of concepts (%i) and dimensions of confusion matrix do not coincide (%i, %i)' %\n",
        "                          (len(concepts), cm.shape[0], cm.shape[1]))\n",
        "\n",
        "    plt.rcParams.update({'font.size': fontsize})\n",
        "\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm_normalized\n",
        "        print(cm)\n",
        "\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm, vmin=np.min(cm), vmax=np.max(cm), alpha=0.8, cmap=cmap)\n",
        "\n",
        "    fig.colorbar(cax)\n",
        "    ax.xaxis.tick_bottom()\n",
        "    plt.ylabel('True label', fontweight='bold')\n",
        "    plt.xlabel('Predicted label', fontweight='bold')\n",
        "\n",
        "    if show_labels:\n",
        "        n_labels = len(concepts)\n",
        "        ax.set_xticklabels(concepts)\n",
        "        ax.set_yticklabels(concepts)\n",
        "#         plt.xticks(np.arange(0, n_labels, 1.0), rotation='vertical')\n",
        "        plt.xticks(np.arange(0, n_labels, 1.0), rotation=45)\n",
        "        plt.yticks(np.arange(0, n_labels, 1.0))\n",
        "    else:\n",
        "        plt.axis('off')\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    if show_text:\n",
        "        # http://stackoverflow.com/questions/21712047/matplotlib-imshow-matshow-display-values-on-plot\n",
        "        min_val, max_val = 0, len(concepts)\n",
        "        ind_array = np.arange(min_val, max_val, 1.0)\n",
        "        x, y = np.meshgrid(ind_array, ind_array)\n",
        "        for i, (x_val, y_val) in enumerate(zip(x.flatten(), y.flatten())):\n",
        "            c = cm[int(x_val), int(y_val)]\n",
        "            ax.text(y_val, x_val, format(c, fmt), va='center', ha='center')\n",
        "\n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path)\n",
        "\n",
        "class_dictionary = {3: 'dog_bark', 2: 'children_playing', 1: 'car_horn', 0: 'air_conditioner', 9: 'street_music', 6: 'gun_shot', 8: 'siren', 5: 'engine_idling', 7: 'jackhammer', 4: 'drilling'}\n",
        "classes = [class_dictionary[key] for key in sorted(class_dictionary.keys())]\n",
        "\n",
        "plot_confusion_matrix(matrix, classes)\n"
      ],
      "metadata": {
        "id": "2HyGEBi66e4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}